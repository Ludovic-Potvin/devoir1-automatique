{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025c9245-958d-4090-97de-366ea244bce7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Nom: Potvin\n",
    "Prenom: Ludovic\n",
    "\n",
    "Ce travail est divise en 3 etapes cle.\n",
    "- Le remplacement des donnees manquantes.\n",
    "- L'ajustement des outliers.\n",
    "- La jointure de d'autre dataset au dataset customer\n",
    "\n",
    "Le resultat final est dans un seul pipeline.\n",
    "\n",
    "> Note: Il y a aussi des etapes de normalisation dans le pipeline, tel que OneHotEncoder et StandardScaler, car ils vont facilite le machine learning pour le devoir 2.\n",
    "\n",
    "# Q3.1 Reproduction des etapes 2 a 4 d'un projet de ML\n",
    "Cette question sera repondu a travers la reponse au autres questions, pour l'instant simplement importer les donnees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e045f67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "num_attribs = ['age', 'pages', 'News_click']\n",
    "cat_attribs = ['first_item_prize', 'gender', 'ReBuy', 'country', 'revenue']\n",
    "\n",
    "customer = pd.read_csv('Customer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a21ac44-a652-41d2-a165-aa93b05a7a36",
   "metadata": {},
   "source": [
    "# Q3.2 Nettoyage des donnees du dataset de base\n",
    "Premiere etapes de nettoyage et de prise de conscience du dataset\n",
    "# Q3.2.1 Remplacement des donnees manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3eec78-57f1-4ffa-b381-5f66b59dd435",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer.info()\n",
    "print(customer.isna().sum())\n",
    "print(customer.isnull().sum())\n",
    "\n",
    "question_marks = (customer == '?').sum()\n",
    "print('==Question mark==')\n",
    "print(question_marks)\n",
    "\n",
    "customer.describe(include='all')\n",
    "customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da52319-8885-4140-9ec1-6e6f0d44764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "customer.hist(bins=50, figsize=(10,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f67d39-3f98-4f9c-b76c-01d192b20026",
   "metadata": {},
   "source": [
    "Il n'y a pas de valeur null ou de NaN dans le dataset, il y a cependant quelque '?' dans la column first_item_prize.\n",
    "La fonction suivante va permettre de les remplacer pour des NaN.\n",
    "On pourra ensuite remplacer les NaN pour la mediane dans le pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a9b65-32f0-4262-9d05-dfdf5c365c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_question_with_nan(X):\n",
    "    X_copy = X.copy()\n",
    "    X_copy = X_copy.replace('?', np.nan)\n",
    "    return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf5c14-de70-48e6-8bd2-b94db7473053",
   "metadata": {},
   "source": [
    "# 3.2.2 Remplacement des donnees aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de24492-8e84-4f15-9c66-e5a1273ca612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for col in num_attribs:\n",
    "    plt.figure(figsize=(5,2))\n",
    "    customer.boxplot(column=col)\n",
    "    plt.title(f\"Boxplot de {col}\")\n",
    "    plt.ylabel(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed50fb0-1ecb-423d-b2a2-97f4524f327f",
   "metadata": {},
   "source": [
    "Avec c'est graphique, il est possible d'observer que les pages et les ages ont tout les deux des outliers. La fonction suivante va permettre de ramener les outliers avec les autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b50f26-6039-4a3a-ba46-ed12613fd353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_amplitude(X):\n",
    "    X_copy = X.copy()\n",
    "    for col in X_copy:\n",
    "        col_data = X_copy[col]\n",
    "\n",
    "        Q1 = np.percentile(col_data, 25)\n",
    "        Q3 = np.percentile(col_data, 75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Remplacer les valeurs < lower par Q1\n",
    "        X_copy[col] = np.where(X_copy[col] < lower, Q1, X_copy[col])\n",
    "        # Remplacer les valeurs > upper par Q3\n",
    "        X_copy[col] = np.where(X_copy[col] > upper, Q3, X_copy[col])\n",
    "\n",
    "    return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aedaa70-ed9c-4ab1-af6d-d5353846dbb2",
   "metadata": {},
   "source": [
    "# Q3.3 Enrichissement des donnees\n",
    "## Exploration des autres datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfec563-dfea-41ab-a18c-e219fbb8c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP = pd.read_csv('CountryGDP.csv')\n",
    "GDP.info()\n",
    "GDP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edee591-da8f-4301-a23d-3f9c57c1c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('CountryPopulation.csv')\n",
    "population.info()\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58701c4-7f14-4ee3-bb00-aca5c38fa608",
   "metadata": {},
   "source": [
    "La fonction suivante va permettre de joindre les datasets de CountryPopulation et CountryGDP au dataset customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d4f44f-00d7-4467-b357-774c74e78461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichissement_population_pib(X, PIB=True):\n",
    "    X_copy = X.copy()\n",
    "\n",
    "    population = pd.read_csv('CountryPopulation.csv')\n",
    "    population.rename(columns={\"Country\": \"country\"}, inplace=True)\n",
    "    X_copy = pd.merge(X_copy, population, on='country') \n",
    "    \n",
    "    if PIB:\n",
    "        GDP = pd.read_csv('CountryGDP.csv')\n",
    "        GDP.rename(columns={\"Country\": \"country\"}, inplace=True)\n",
    "        X_copy = pd.merge(X_copy, GDP, on='country') \n",
    "\n",
    "    return X_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd058f-bb82-4226-b23e-1afd793d2b96",
   "metadata": {},
   "source": [
    "# Pipeline final\n",
    "Voici le pipeline avec chaque etapes. A note qu'il est possible d'enlever le StandardScaler et le OnHotEncoder pour lire plus clairement le resultat. Les deux etapes sont presentes pour facilite le machine learning dans le devoir 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50290ee-792f-418e-b75f-5e0167d1d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "\n",
    "enrichissement_transformer = FunctionTransformer(enrichissement_population_pib, validate=False, kw_args={\"PIB\": True})\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"Replace question mark\", FunctionTransformer(replace_question_with_nan, validate=False)),\n",
    "    (\"iqr outliers\", FunctionTransformer(iqr_amplitude, validate=False)),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, num_attribs + ['population', 'GDP_inhab']),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('enrich', enrichissement_transformer),\n",
    "    ('preprocessor', preprocessor),\n",
    "])\n",
    "\n",
    "clean_customer = full_pipeline.fit_transform(customer)\n",
    "customer_array = clean_customer.toarray()\n",
    "pd.DataFrame(customer_array).info()\n",
    "pd.DataFrame(customer_array).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
